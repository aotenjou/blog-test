---
title: 3.22
date: 2025-03-22 19:27:53
tags:
---
 <!-- more -->
读论文。
## 1.PVLDB：memformer

**idea**：分块循环图学习，全局attention,交替记忆增强器
**knowledge**：
1. 正则化：**防止过拟合！** 显式正则化/隐式正则化，机器学习基础内容，回顾一下。
显：
- L1（lasso）正则化：向损失函数添加权重**绝对值之和**作为惩罚，迫使部分权重趋近于0。
- L2（ridge）正则化：向损失函数添加权重**平方之和**作为惩罚，限制权重幅度使其平滑。
- Dropout：训练时，关闭部分神经元（概率p），迫使网络学习冗余表示。测试时激活所有，权重乘（1-p）保持期望值。
- 弹性网络：L1L2搞在一起。
隐：
- 数据增强：训练数据加噪/旋转，增加数据多样性。
- 早停：验证集性能不再提升时终止训练，防止过拟合。
- 批量归一化：每层输入标准化，缓解内部协变量偏移。

2. 子序列建模：
- 通道独立/线性模型：每个变量单独并行处理，隐式参数共享/处理后数据整合。
- transformer类：注意力机制，异常值敏感。

3. 交替记忆增强
- 局部增强器：局部动态特征，细粒度关联建模。
- 全局增强器：全局模式，增强抗干扰。
- 交替训练机制。

